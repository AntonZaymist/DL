{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import datetime, date\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "pd.set_option('display.max_columns', 8)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.width', 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Исследование CSV-файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
      "['7/21/2014', '83.46', '83.53', '81.81', '81.93', '2359300']\n",
      "['7/18/2014', '83.3', '83.4', '82.52', '83.35', '4020800']\n",
      "['7/17/2014', '84.35', '84.63', '83.33', '83.63', '1974000']\n",
      "['7/16/2014', '83.77', '84.91', '83.66', '84.91', '1755600']\n",
      "['7/15/2014', '84.3', '84.38', '83.2', '83.58', '1874700']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open(\"C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/msft.csv\") as file:\n",
    "    reader = csv.reader(file, delimiter=',')\n",
    "    for i,row in enumerate(reader):\n",
    "        print(row)\n",
    "        if(i>=5):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Чтение CSV-файла в датафрейме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume\n",
       "0  7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       "1  7/18/2014  83.30  83.40  82.52  83.35  4020800\n",
       "2  7/17/2014  84.35  84.63  83.33  83.63  1974000\n",
       "3  7/16/2014  83.77  84.91  83.66  84.91  1755600\n",
       "4  7/15/2014  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считываем msft.csv в датафрейм\n",
    "msft = pd.read_csv(\"C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/msft.csv\")\n",
    "msft[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Указание индекса столбца при чтении CSV-файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Open   High    Low  Close   Volume\n",
       "Date                                          \n",
       "7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       "7/18/2014  83.30  83.40  82.52  83.35  4020800\n",
       "7/17/2014  84.35  84.63  83.33  83.63  1974000\n",
       "7/16/2014  83.77  84.91  83.66  84.91  1755600\n",
       "7/15/2014  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#используем столбец 0 в качестве индекса\n",
    "msft = pd.read_csv(\"C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/msft.csv\", index_col=0)\n",
    "msft[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Вывод и спецификация типа данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open      float64\n",
       "High      float64\n",
       "Low       float64\n",
       "Close     float64\n",
       "Volume      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# исследуем типы столбцов в этом датафрейме\n",
    "msft.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date       object\n",
       "Open      float64\n",
       "High      float64\n",
       "Low       float64\n",
       "Close     float64\n",
       "Volume    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# указываем что столбец Volume должен иметь тип float64\n",
    "msft = pd.read_csv(\"C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/msft.csv\",\n",
    "                  dtype={'Volume': np.float64})\n",
    "msft.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Указание имен столбцов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        date   open   high    low  close   volume\n",
       "0  7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       "1  7/18/2014  83.30  83.40  82.52  83.35  4020800\n",
       "2  7/17/2014  84.35  84.63  83.33  83.63  1974000\n",
       "3  7/16/2014  83.77  84.91  83.66  84.91  1755600\n",
       "4  7/15/2014  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Задаем новый набор имен для столбцов все имеют ниний регистр, head=0 задает строку заголовку\n",
    "df = pd.read_csv(\"C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/msft.csv\",\n",
    "                   header=0,\n",
    "                   names=['date','open','high','low','close','volume')]\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Указание конкретных столбцов для загрузки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           Close\n",
       "Date            \n",
       "7/21/2014  81.93\n",
       "7/18/2014  83.35\n",
       "7/17/2014  83.63\n",
       "7/16/2014  84.91\n",
       "7/15/2014  83.58"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считываем в данных только столбцы Date и Close и индексируем по столбцу Date\n",
    "df2 = pd.read_csv(\"C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/msft.csv\",\n",
    "                 usecols=['Date','Close'],\n",
    "                 index_col=['Date'])\n",
    "df2[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Сохранение датафрейма в CSV-файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняем датафрейм df2 в новый csv-файл\n",
    "# задаем имя индекса как date\n",
    "df2.to_csv(\"C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/msft_modified.csv\", index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date', 'Close']\n",
      "['7/21/2014', '81.93']\n",
      "['7/18/2014', '83.35']\n",
      "['7/17/2014', '83.63']\n",
      "['7/16/2014', '84.91']\n",
      "['7/15/2014', '83.58']\n"
     ]
    }
   ],
   "source": [
    "# с помощью модуля csv взглянем на первые 5 строк CSV файла\n",
    "with open(\"C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/msft_modified.csv\") as file:\n",
    "    reader = csv.reader(file, delimiter=',')\n",
    "    for i,row in enumerate(reader):\n",
    "        print(row)\n",
    "        if(i>=5):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Работа с данными, в которых используются разделители полей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume\n",
       "0  7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       "1  7/18/2014  83.30  83.40  82.52  83.35  4020800\n",
       "2  7/17/2014  84.35  84.63  83.33  83.63  1974000\n",
       "3  7/16/2014  83.77  84.91  83.66  84.91  1755600\n",
       "4  7/15/2014  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# используем функцию read_table с параметром sep=',', что бы прочитать CSV файл\n",
    "df = pd.read_table(\"C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/msft.csv\", sep=',')\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['|Date|Open|High|Low|Close|Volume']\n",
      "['0|7/21/2014|83.46|83.53|81.81|81.93|2359300']\n",
      "['1|7/18/2014|83.3|83.4|82.52|83.35|4020800']\n",
      "['2|7/17/2014|84.35|84.63|83.33|83.63|1974000']\n",
      "['3|7/16/2014|83.77|84.91|83.66|84.91|1755600']\n",
      "['4|7/15/2014|84.3|84.38|83.2|83.58|1874700']\n"
     ]
    }
   ],
   "source": [
    "# сохраняем как данные, в которых разделителем является вертикальная черта\n",
    "df.to_csv(\"C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/msft_piped.csv\", sep='|')\n",
    "# смотрим, как сработал программный код\n",
    "with open(\"C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/msft_piped.csv\") as file:\n",
    "    reader = csv.reader(file, delimiter=',')\n",
    "    for i,row in enumerate(reader):\n",
    "        print(row)\n",
    "        if(i>=5):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Обработка загрязненных данных, в которых используются разделители полей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is fun because the data does not start on the first line', '', '', '', '', '']\n",
      "['Date', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
      "['', '', '', '', '', '']\n",
      "['And there is space between the header row and data', '', '', '', '', '']\n",
      "['7/21/2014', '83.46', '83.53', '81.81', '81.93', '2359300']\n",
      "['7/18/2014', '83.3', '83.4', '82.52', '83.35', '4020800']\n",
      "['7/17/2014', '84.35', '84.63', '83.33', '83.63', '1974000']\n"
     ]
    }
   ],
   "source": [
    "with open(\"C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/msft2.csv\") as file:\n",
    "    reader = csv.reader(file, delimiter=',')\n",
    "    for i,row in enumerate(reader):\n",
    "        print(row)\n",
    "        if(i>=6):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume\n",
       "0  7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       "1  7/18/2014  83.30  83.40  82.52  83.35  4020800\n",
       "2  7/17/2014  84.35  84.63  83.33  83.63  1974000\n",
       "3  7/16/2014  83.77  84.91  83.66  84.91  1755600\n",
       "4  7/15/2014  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считываем данные, пропустив строки 0,2 и 3\n",
    "df = pd.read_csv(\"C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/msft2.csv\", skiprows=[0,2,3])\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
      "['7/21/2014', '83.46', '83.53', '81.81', '81.93', '2359300']\n",
      "['7/18/2014', '83.3', '83.4', '82.52', '83.35', '4020800']\n",
      "[]\n",
      "['Uh oh', ' there is stuff at the end.']\n"
     ]
    }
   ],
   "source": [
    "with open(\"C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/msft_with_footer.csv\") as file:\n",
    "    reader = csv.reader(file, delimiter=',')\n",
    "    for row in reader:\n",
    "        print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume\n",
       "0  7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       "1  7/18/2014  83.30  83.40  82.52  83.35  4020800"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/msft_with_footer.csv\", \n",
    "                skipfooter=2,\n",
    "                engine='python')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume\n",
       "0  7/21/2014  83.46  83.53  81.81  81.93  2359300\n",
       "1  7/18/2014  83.30  83.40  82.52  83.35  4020800\n",
       "2  7/17/2014  84.35  84.63  83.33  83.63  1974000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считаем только первые три строки\n",
    "pd.read_csv(\"C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/msft.csv\", nrows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        date   open   high    low  close   volume\n",
       "0   3/3/2014  80.35  81.31  79.91  79.97  5004100\n",
       "1  2/28/2014  82.40  83.42  82.17  83.42  2853200\n",
       "2  2/27/2014  84.06  84.63  81.63  82.00  3676800\n",
       "3  2/26/2014  82.92  84.03  82.43  83.81  2623600\n",
       "4  2/25/2014  83.80  83.80  81.72  83.08  3579100"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# пропускаем 100 строк, а затем считываем следующие 5 строк\n",
    "pd.read_csv(\"C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/msft.csv\", skiprows=100, nrows=5,\n",
    "           header=0,\n",
    "           names=['date','open','high','low','close','volume'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Чтение и запись в формате Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume\n",
       "0 2014-07-21  83.46  83.53  81.81  81.93  2359300\n",
       "1 2014-07-18  83.30  83.40  82.52  83.35  4020800\n",
       "2 2014-07-17  84.35  84.63  83.33  83.63  1974000\n",
       "3 2014-07-16  83.77  84.91  83.66  84.91  1755600\n",
       "4 2014-07-15  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#считываем файл Excel считываем только данные первого рабочего листа (msft в данном случае)\n",
    "df = pd.read_excel(\"C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/stocks.xlsx\")\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close    Volume\n",
       "0 2014-07-21  94.99  95.00  93.72  93.94  38887700\n",
       "1 2014-07-18  93.62  94.74  93.02  94.43  49898600\n",
       "2 2014-07-17  95.03  95.28  92.57  93.09  57152000\n",
       "3 2014-07-16  96.97  97.10  94.74  94.78  53396300\n",
       "4 2014-07-15  96.80  96.85  95.03  95.32  45477900"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считываем данные рабочего листа aapl\n",
    "aapl = pd.read_excel('C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/stocks.xlsx', sheet_name='aapl')\n",
    "aapl[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняем XLS файл в рабочем листе 'Sheet1'\n",
    "df.to_excel('C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/stocks2.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# записываем, задав имя рабочего листа MSFT\n",
    "df.to_excel('C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/stocks_msft.xls', sheet_name='MSFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import ExcelWriter\n",
    "with ExcelWriter('C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/stocks.xlsx') as writer:\n",
    "    aapl.to_excel(writer, sheet_name='AAPL')\n",
    "    df.to_excel(writer, sheet_name='MSFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# записываем в Xlsx\n",
    "df.to_excel('C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/msft2.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Чтение и запись JSON - файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Close': {'0': 81.93, '1': 83.35, '2': 83.63, '3': 84.91, '4': 83.58},\n",
      " 'Date': {'0': 1405900800000,\n",
      "          '1': 1405641600000,\n",
      "          '2': 1405555200000,\n",
      "          '3': 1405468800000,\n",
      "          '4': 1405382400000},\n",
      " 'High': {'0': 83.53, '1': 83.4, '2': 84.63, '3': 84.91, '4': 84.38},\n",
      " 'Low': {'0': 81.81, '1': 82.52, '2': 83.33, '3': 83.66, '4': 83.2},\n",
      " 'Open': {'0': 83.46, '1': 83.3, '2': 84.35, '3': 83.77, '4': 84.3},\n",
      " 'Volume': {'0': 2359300,\n",
      "            '1': 4020800,\n",
      "            '2': 1974000,\n",
      "            '3': 1755600,\n",
      "            '4': 1874700}}\n"
     ]
    }
   ],
   "source": [
    "# записываем даные эксель в JSON-файл\n",
    "df[:5].to_json('C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/stocks.json')\n",
    "# теперь взглянем на JSON-файл\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "with open('C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/stocks.json') as data_file:\n",
    "    data = json.load(data_file)\n",
    "    \n",
    "pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume\n",
       "0 2014-07-21  83.46  83.53  81.81  81.93  2359300\n",
       "1 2014-07-18  83.30  83.40  82.52  83.35  4020800\n",
       "2 2014-07-17  84.35  84.63  83.33  83.63  1974000\n",
       "3 2014-07-16  83.77  84.91  83.66  84.91  1755600\n",
       "4 2014-07-15  84.30  84.38  83.20  83.58  1874700"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считываем данные в формате JSON \n",
    "df_from_json = pd.read_json('C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/stocks.json')\n",
    "df_from_json[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Чтение HTML-файлов из интернета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#задаем URL-адрес HTML-файла\n",
    "url = \"http://www.fdic.gov/bank/individual/failed/banklist.html\"\n",
    "# читаем его\n",
    "banks = pd.read_html(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                             Bank Name     City\n",
       "0     City National Bank of New Jersey   Newark\n",
       "1                        Resolute Bank   Maumee\n",
       "2                Louisa Community Bank   Louisa\n",
       "3                 The Enloe State Bank   Cooper\n",
       "4  Washington Federal Bank for Savings  Chicago"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверяем, как была прочитана часть первой таблицы\n",
    "banks[0][0:5].iloc[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#считаваем данные о котировках акций\n",
    "df = pd.read_excel('C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/stocks.xlsx')\n",
    "# записавыем первые две строки в HTML\n",
    "df.head(2).to_html('C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/stocks.html')\n",
    "# смотрим HTML-файл в браузере\n",
    "import webbrowser\n",
    "webbrowser.open('C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/stocks.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Чтение и запись HDF5-файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pandas.io.pytables.HDFStore'>\n",
       "File path: C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/store.h5"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# задаем стартовое значение генератора случайных чисел для получения воспроизводимых результатов\n",
    "np.random.seed(123456)\n",
    "# создаем датафрейм, состоящий из дат и случайных чисел, записанных в трех столбцах\n",
    "df = pd.DataFrame(np.random.randn(8,3),\n",
    "                 index=pd.date_range('1/1/2000', periods=8),\n",
    "                 columns=['A','B','C'])\n",
    "# создаем хранилище HDF5\n",
    "store = pd.HDFStore('C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/store.h5')\n",
    "store['df'] = df # сохранение произошло здесь\n",
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                   A         B         C\n",
       "2000-01-01  0.469112 -0.282863 -1.509059\n",
       "2000-01-02 -1.135632  1.212112 -0.173215\n",
       "2000-01-03  0.119209 -1.044236 -0.861849\n",
       "2000-01-04 -2.104569 -0.494929  1.071804\n",
       "2000-01-05  0.721555 -0.706771 -1.039575"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считываем данные хранилища HDF5\n",
    "store = pd.HDFStore('C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/store.h5')\n",
    "df = store['df']\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                   A         B         C\n",
       "2000-01-01  1.000000 -0.282863 -1.509059\n",
       "2000-01-02 -1.135632  1.212112 -0.173215\n",
       "2000-01-03  0.119209 -1.044236 -0.861849\n",
       "2000-01-04 -2.104569 -0.494929  1.071804\n",
       "2000-01-05  0.721555 -0.706771 -1.039575"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# этот код меняет датафрейм, но изменения не сохраняются\n",
    "df.iloc[0].A=1\n",
    "# чтобы сохранить изменения, присваеваем объект DataFrame объекту- хранилищу HDF5\n",
    "store['df'] = df\n",
    "#теперь изменения сохранены\n",
    "# следуюзий код загружает хранилище и выводит первые две строки, демонстрируя, что сохранение выполнено\n",
    "pd.HDFStore('C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/store.h5')['df'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Загрузка CSV-файлов из интерента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-e9b5880e1c3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m msft_hist = pd.read_csv(\n\u001b[0;32m      3\u001b[0m     \u001b[1;34m\"http://www.google.com/finance/historical?\"\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;34m\"q=NASDAQ:MSFT&startdate=Apr+01%2C+2017&\"\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \"enddate=Apr+30%2C+2017&output=csv\")\n\u001b[0;32m      6\u001b[0m \u001b[0mmsft_hist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m     \u001b[1;31m# See https://github.com/python/mypy/issues/1297\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     fp_or_buf, _, compression, should_close = get_filepath_or_buffer(\n\u001b[1;32m--> 440\u001b[1;33m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m     )\n\u001b[0;32m    442\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m         \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m         \u001b[0mcontent_encoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Content-Encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"gzip\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    529\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             response = self.parent.error(\n\u001b[1;32m--> 641\u001b[1;33m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    567\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'http_error_default'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 569\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[1;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    501\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    647\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "#Считывает csv непосредственно из google finance по url фдресу\n",
    "msft_hist = pd.read_csv(\n",
    "    \"http://www.google.com/finance/historical?\" +\n",
    "    \"q=NASDAQ:MSFT&startdate=Apr+01%2C+2017&\" +\n",
    "    \"enddate=Apr+30%2C+2017&output=csv\")\n",
    "msft_hist[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Чтение из БД sql и запись в БД sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем библиотеку SQLite\n",
    "import sqlite3\n",
    "# считываем данные о котировках акций из CSV-файла\n",
    "msft = pd.read_csv('C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/msft.csv')\n",
    "msft['Symbol']='MSFT'\n",
    "aapl = pd.read_csv('C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/aapl.csv')\n",
    "aapl['Symbol']='AAPL'\n",
    "\n",
    "#создаем подключение\n",
    "connection = sqlite3.connect('C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/stocks.sqlite')\n",
    "# .to_sql() создает базу SQL для хранения датафреймов в указанной таблице, \n",
    "# if_exists задает действие, которое нужно выполнить в том случае если таблица уже существует\n",
    "msft.to_sql('STOCK_DATA', connection, if_exists='replace')\n",
    "msft.to_sql('STOCK_DATA', connection, if_exists='append')\n",
    "\n",
    "# подверждаем отправку данных в базу и закрываем подключение\n",
    "connection.commit()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Date   Open   High    Low  Close   Volume Symbol\n",
       "index                                                       \n",
       "0      7/21/2014  83.46  83.53  81.81  81.93  2359300   MSFT\n",
       "1      7/18/2014  83.30  83.40  82.52  83.35  4020800   MSFT\n",
       "2      7/17/2014  84.35  84.63  83.33  83.63  1974000   MSFT\n",
       "3      7/16/2014  83.77  84.91  83.66  84.91  1755600   MSFT\n",
       "4      7/15/2014  84.30  84.38  83.20  83.58  1874700   MSFT"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# подключаемся к файлу БД\n",
    "connection = sqlite3.connect('C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/stocks.sqlite')\n",
    "\n",
    "# запрос всех записей в STOCK_DATA\n",
    "# возвращает датафрейм\n",
    "# index_col задает столбец, который нужно сделаь индексом датафрейма \n",
    "stocks = pd.io.sql.read_sql('SELECT * FROM STOCK_DATA;',\n",
    "                           connection, index_col='index')\n",
    "\n",
    "# закрываем подключение\n",
    "connection.close()\n",
    "\n",
    "# выводим первые 5 наблюдений в извлеченных данных\n",
    "stocks[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Date   Open   High    Low  Close    Volume Symbol\n",
       "index                                                        \n",
       "1081   5/21/2010  42.22  42.35  40.99  42.00  33610800   MSFT\n",
       "1097   4/29/2010  46.80  46.95  44.65  45.92  47076200   MSFT\n",
       "1826   6/15/2007  89.80  92.10  89.55  92.04  30656400   MSFT\n",
       "3455   3/16/2001  47.00  47.80  46.10  45.33  40806400   MSFT\n",
       "3712   3/17/2000  49.50  50.00  48.29  50.00  50860500   MSFT\n",
       "1081   5/21/2010  42.22  42.35  40.99  42.00  33610800   MSFT\n",
       "1097   4/29/2010  46.80  46.95  44.65  45.92  47076200   MSFT\n",
       "1826   6/15/2007  89.80  92.10  89.55  92.04  30656400   MSFT\n",
       "3455   3/16/2001  47.00  47.80  46.10  45.33  40806400   MSFT\n",
       "3712   3/17/2000  49.50  50.00  48.29  50.00  50860500   MSFT"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection = sqlite3.connect('C:/Users/Anton.Zaimist/Desktop/pandas/Learning_pandas_russian_translation/Data/stocks.sqlite')\n",
    "query = \"select * from stock_data where volume > 29200100 and symbol='MSFT';\"\n",
    "items = pd.io.sql.read_sql(query, connection, index_col='index')\n",
    "connection.close()\n",
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Загрузка данных с удаленных сервисов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Загрузка данных о котировках акций с веб-сервисов Yahoo и google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader as pdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                 High        Low       Open      Close    Volume  Adj Close\n",
       "Date                                                                       \n",
       "2016-04-01  55.610001  54.570000  55.049999  55.570000  24399200  51.614536\n",
       "2016-04-04  55.660000  55.000000  55.430000  55.430000  18928800  51.484501\n",
       "2016-04-05  55.299999  54.459999  55.189999  54.560001  19272300  50.676422\n",
       "2016-04-06  55.200001  54.209999  54.360001  55.119999  21188700  51.196564\n",
       "2016-04-07  54.910000  54.230000  54.869999  54.459999  19225100  50.583542"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считываем данные с google и выводим первые 5 строк\n",
    "start = datetime(2016,4,1)\n",
    "end = datetime(2016,4,30)\n",
    "goog = pdr.data.DataReader('MSFT', 'yahoo', start, end)\n",
    "goog[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Загрузка данных об опционах с веб-сервиса Google Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImmediateDeprecationError",
     "evalue": "\nYahoo Options has been immediately deprecated due to large breaks in the API without the\nintroduction of a stable replacement. Pull Requests to re-enable these data\nconnectors are welcome.\n\nSee https://github.com/pydata/pandas-datareader/issues\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImmediateDeprecationError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-e5c314d26de1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# считываем данные об опционах\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0moptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpdr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'MSFT'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'yahoo'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpiry_dates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas_datareader\\data.py\u001b[0m in \u001b[0;36mOptions\u001b[1;34m(symbol, data_source, session)\u001b[0m\n\u001b[0;32m    677\u001b[0m         \u001b[0mdata_source\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"yahoo\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdata_source\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"yahoo\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 679\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mImmediateDeprecationError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEP_ERROR_MSG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Yahoo Options\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    680\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mYahooOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImmediateDeprecationError\u001b[0m: \nYahoo Options has been immediately deprecated due to large breaks in the API without the\nintroduction of a stable replacement. Pull Requests to re-enable these data\nconnectors are welcome.\n\nSee https://github.com/pydata/pandas-datareader/issues\n"
     ]
    }
   ],
   "source": [
    "# считываем данные об опционах\n",
    "options = pdr.data.Options('MSFT', 'yahoo')\n",
    "options.expiry_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'options' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-69c07f647ecc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_options_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpiry\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpiry_dates\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'options' is not defined"
     ]
    }
   ],
   "source": [
    "data = options.get_options_data(expiry=options.expiry_dates[0])\n",
    "data.iloc[:5,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'loc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-f67216fea80a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'put'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'loc'"
     ]
    }
   ],
   "source": [
    "data.loc[(30, slice(None), 'put'), :].iloc[0:5, 0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Загрузка БД по экономической статистике федерального резервного банка Сент-Луиса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  GDP\n",
       "DATE                 \n",
       "2018-01-01  20163.159\n",
       "2018-04-01  20510.177\n",
       "2018-07-01  20749.752\n",
       "2018-10-01  20897.804\n",
       "2019-01-01  21098.827"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считываем данные по GPD из FRED\n",
    "gdp = pdr.data.FredReader('GDP',\n",
    "                         date(2018,1,1),\n",
    "                         date(2019,1,26))\n",
    "gdp.read()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            A576RC1A027NBEA\n",
       "DATE                       \n",
       "1929-01-01             50.5\n",
       "1930-01-01             46.2\n",
       "1931-01-01             39.2\n",
       "1932-01-01             30.5\n",
       "1933-01-01             29.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получаем данные по показателю Compensation of employees: wages and salaries\n",
    "pdr.data.FredReader('A576RC1A027NBEA',\n",
    "                   date(1929,1,1),\n",
    "                   date(2013,1,1)).read()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Загрузка данных Кеннета Френча"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Mkt-RF   SMB   HML   WML   RF\n",
       "Date                                  \n",
       "2015-02    5.93 -0.17 -0.30 -1.93  0.0\n",
       "2015-03   -1.20  1.54 -0.89  2.07  0.0\n",
       "2015-04    2.71  0.81  2.15 -3.31  0.0\n",
       "2015-05    0.49  1.33 -1.25  4.24  0.0\n",
       "2015-06   -2.10  2.04 -0.94  1.83  0.0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считываем набор данных Global Factors из библиотеки Кеннета Френча\n",
    "factors = pdr.data.FamaFrenchReader('Global_Factors').read()\n",
    "factors[0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Загрузка данных всемирного банка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     id                                     name\n",
       "0    1.0.HCount.1.90usd          Poverty Headcount ($1.90 a day)\n",
       "1     1.0.HCount.2.5usd          Poverty Headcount ($2.50 a day)\n",
       "2  1.0.HCount.Mid10to50    Middle Class ($10-50 a day) Headcount\n",
       "3       1.0.HCount.Ofcl  Official Moderate Poverty Rate-National\n",
       "4   1.0.HCount.Poor4uds             Poverty Headcount ($4 a day)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas_datareader import wb\n",
    "# извлекаем все индикаторы\n",
    "all_indicators = pdr.wb.get_indicators()\n",
    "# выводим первые 5\n",
    "all_indicators.iloc[:5,:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                      id                                               name\n",
       "10246        SE.SCH.LIFE  School life expectancy, primary to tertiary, b...\n",
       "10247     SE.SCH.LIFE.FE  School life expectancy, primary to tertiary, f...\n",
       "10248     SE.SCH.LIFE.MA  School life expectancy, primary to tertiary, m...\n",
       "11663  SP.DYN.LE00.FE.IN           Life expectancy at birth, female (years)\n",
       "11664     SP.DYN.LE00.IN            Life expectancy at birth, total (years)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# поиск индикаторов, связанных с продолжительностью жизни\n",
    "le_indicators = pdr.wb.search('life expectancy')\n",
    "# выводим первые 3 строки\n",
    "le_indicators.iloc[:5,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          name       capitalCity iso2c\n",
       "0        Aruba        Oranjestad    AW\n",
       "1  Afghanistan             Kabul    AF\n",
       "2       Africa                      A9\n",
       "3       Angola            Luanda    AO\n",
       "4      Albania            Tirane    AL\n",
       "5      Andorra  Andorra la Vella    AD"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получаем полный список стран, показываем код и название\n",
    "countries = pdr.wb.get_countries()\n",
    "# выводим фрагмент списка стран\n",
    "countries.loc[0:5,['name', 'capitalCity', 'iso2c']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                    SP.DYN.LE00.IN\n",
       "country       year                \n",
       "Canada        2014       81.800000\n",
       "              2013       81.748780\n",
       "              2012       81.648780\n",
       "              2011       81.448780\n",
       "              2010       81.246341\n",
       "...                            ...\n",
       "United States 1984       74.563415\n",
       "              1983       74.463415\n",
       "              1982       74.360976\n",
       "              1981       74.009756\n",
       "              1980       73.609756\n",
       "\n",
       "[105 rows x 1 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получаем данные о продолжительности жизни для всех стран с 1980 по 2014 год\n",
    "le_data_all = pdr.wb.download(indicator='SP.DYN.LE00.IN',\n",
    "                             start='1980',\n",
    "                             end='2014')\n",
    "le_data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Canada', 'Mexico', 'United States'], dtype='object', name='country')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# по умолчанию будут возвращены данные только для США, Канады и Мексики\n",
    "le_data_all.index.levels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               SP.DYN.LE00.IN\n",
       "country  year                \n",
       "Aruba    2014          75.583\n",
       "         2013          75.441\n",
       "         2012          75.299\n",
       "         2011          75.158\n",
       "         2010          75.017\n",
       "...                       ...\n",
       "Zimbabwe 1984          61.280\n",
       "         1983          61.025\n",
       "         1982          60.650\n",
       "         1981          60.203\n",
       "         1980          59.731\n",
       "\n",
       "[9240 rows x 1 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# отключаем предупреждение Anaconda\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "# получаем данные о продолжительности жизни для всех стран с 1980 по 2014 год\n",
    "le_data_all = wb.download(indicator='SP.DYN.LE00.IN',\n",
    "                         country = countries['iso2c'],\n",
    "                         start='1980',\n",
    "                         end='2014')\n",
    "le_data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               SP.DYN.LE00.IN                \n",
       "year                     1980    1981    1982\n",
       "country                                      \n",
       "Afghanistan            43.244  43.923  44.617\n",
       "Albania                70.208  70.416  70.635\n",
       "Algeria                58.198  59.519  60.813\n",
       "American Samoa            NaN     NaN     NaN\n",
       "Andorra                   NaN     NaN     NaN"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#le_data_all.pivot(index='country', columns='year')\n",
    "le_data = le_data_all.reset_index().pivot(index='country', \n",
    "                                          columns='year')\n",
    "# смотрим транспортированные данные\n",
    "le_data.iloc[:5,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                year\n",
       "SP.DYN.LE00.IN  1980       Cambodia\n",
       "                1981       Cambodia\n",
       "                1982    Timor-Leste\n",
       "                1983    South Sudan\n",
       "                1984    South Sudan\n",
       "dtype: object"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# определяем для каждого года страну с наименьшей продолжительностью жизни\n",
    "country_with_least_expectancy = le_data.idxmin(axis=0)\n",
    "country_with_least_expectancy[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                year\n",
       "SP.DYN.LE00.IN  1980    27.536\n",
       "                1981    33.342\n",
       "                1982    38.175\n",
       "                1983    39.671\n",
       "                1984    40.005\n",
       "dtype: float64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp = le_data.min(axis=0)\n",
    "exp[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          Country  Expectancy\n",
       "year                         \n",
       "1980     Cambodia      27.536\n",
       "1981     Cambodia      33.342\n",
       "1982  Timor-Leste      38.175\n",
       "1983  South Sudan      39.671\n",
       "1984  South Sudan      40.005\n",
       "...           ...         ...\n",
       "2010      Lesotho      45.100\n",
       "2011      Lesotho      46.207\n",
       "2012      Lesotho      47.416\n",
       "2013      Lesotho      48.663\n",
       "2014      Lesotho      49.891\n",
       "\n",
       "[35 rows x 2 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# этот код объединяет два датафрейма вместе, и мы получаем по каждому году страну с наименьшей продолжителльностью жизни и\n",
    "# наименьшее значение продолжительности жизни\n",
    "least = pd.DataFrame(\n",
    "    data = {'Country': country_with_least_expectancy.values,\n",
    "            'Expectancy': exp.values},\n",
    "    index = country_with_least_expectancy.index.levels[1])\n",
    "least[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
